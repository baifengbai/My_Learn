# python 3.6
# Author:              Scc_hy
# Create date:         2019-12-12
# Function:            统计学习方法
# Version :


import sys, os
from random import random
from time import clock
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy as sp
from scipy.optimize import leastsq
from sklearn.datasets import load_iris
import seaborn as sns
from itertools import combinations
from sklearn.model_selection import train_test_split
from collections import Counter # 将列表都是数，读取成字典
import pprint
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
import pydotplus

def create_data(return_numpy=True):
    """
    载入iris的前一百的数据
    """
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = [i.replace(' (cm)', '') for i in df.columns]
    if return_numpy:
        data = np.array(df.iloc[:100, :])
        out_1, out_2 = data[:, :-1], data[:, -1]
    else:
        out_1, out_2 = df.iloc[:100, :-1], df.iloc[:100, -1]
    return out_1, out_2

# ================================================================
#                   第六章   Logistic
## 条件概率分布表示的分类模型
# ================================================================
## 6.1 
## -------------------------------------

x, y = create_data(True)
x_tr, x_te, y_tr, y_te = train_test_split(x, y, test_size = 0.3)

class Lg_reg_clf():
    def __init__(self, max_iter = 200, lr = 0.01):
        self.max_iter = max_iter
        self.lr = lr
        
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))
    
    def data_matrix(self, x):
        one_x = np.ones((x.shape[0], 1))
        return np.c_[one_x, x]

    def fit(self, x, y):
        dt = self.data_matrix(x)
        m, n = dt.shape
        self.weights = np.zeros((n, 1), dtype=np.float32)

        for iter_ in range(self.max_iter):
            for i in range(m):
                result = self.sigmoid(np.dot(dt[i], self.weights))
                error = y[i] - result
                self.weights += self.lr * error * np.transpose([dt[i]])
        print('LogisticRegression Model(learning_rate={},max_iter={})'.format(
            self.lr, self.max_iter))

    def score(self, X_test, y_test):
        right = 0
        X_test = self.data_matrix(X_test)
        for x, y in zip(X_test, y_test):
            result = np.dot(x, self.weights)
            if (result > 0 and y == 1) or (result < 0 and y == 0):
                right += 1
        return right / len(X_test)


lr_clf = Lg_reg_clf()
lr_clf.fit(x_tr, y_tr)
lr_clf.score(x_te, y_te)
